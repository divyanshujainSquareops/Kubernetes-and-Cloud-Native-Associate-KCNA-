## Observability Fundamentals
- Observability - The ability to understand and measure the state of a system based
upon data generated by the system
- Observability allows you to generate actionable outputs from unexpected scenarios
in dynamic environments
- Observability will help:
    1. Give better insight into the internal workings of a system/application
    2. Speed up troubleshooting
    3. Detect hard to catch problems
    4. Monitor performance of an application
    5. Improve cross-team collaboration
- purpose=better understand the internals of system.
- 3 pillars of observablity
    1. logging=Logs are records of events that have occurred and encapsulate information about the specific event
     Logs are comprised of:
        • Timestamp of when the log occurred
        • Message containing information
    2. metrics=Metrics provide information about the state of a system using numerical values.
    - ex:-
        • CPU Load
        • Number of open files
        • HTTP response times
        • Number of errors
    - The data collected can be aggregated over time and graphed using visualization tools to identify trends over time.
    - Metrics contain 4 pieces of information:
        1. Metric name =(node_filesystem_avail_bytes)
        2. Value - most recent or current value of the metric.(5000)
        3. Timestamp for the metric.(4:30AM 12/1/22)
        4. Dimensions - additional information about the metric.({fstype="vfat", mountpoint="/home"})
       ex:-node_filesystem_avail_bytes{fstype="vfat", mountpoint="/home"} 5000 4:30AM 12/1/22
    3. traces=
    - allow you to follow operations as they traverses through various systems & services.
    - Traces help us to connect dots on how processes and svc work together.
    - Each trace has a trace-id that can be used to identify a request as it traverses the system
    - Individual events forming a trace are called spans.
    - Each span tracks the following:
        • Start time
        • Duration
        • Parent-id

# prometheus =
- Prometheus is a monitoring solution that is responsible for collecting and aggregating metrics.

## SLO/SLA/SLI
- Service Level Indicator(SLI) - quantitative measure of some aspect of the level of service that is provided
    it is a metric that we can use to measure the quality of servie.
    Common SLIs:
    • Request Latency
    • Error Rate
    • Saturation
    • Throughput
    • Availability

- Service Level Object(SLO) - target value or range for an SLI
    - SLOs should be directly related to the customer experience. The main purpose of the SLO is to quantify reliability of a product to a customer.
    ex:-
    SLI - Latency
    SLO - Latency < 100ms
    SLI - availability
    SLO - 99.9% uptime
- Service Level Agreement(SLA) - contract between a vendor and a user that guarantees a certain SLO

## Prometheus Use Case
- prometheus collect metrics from multiple data centers.
- it has builtin dashboarding utilities that it can use to present data in single page.
- prometheus has built-in alerting so that it can track various metrics.
- prometheus can plat a graph b/w 2 things.prometheus have built-in dashboard and visulization tool.
    ex:- it can plot graph b/w average latency vs average file size.

## Prometheus Basics
- Prometheus is an open-source monitoring tool that collects metrics data,and provide tools to visualize the collected data
- In addition, Prometheus allows you to generate alerts when metrics reach a user specified threshold
- Prometheus collects metrics by scraping targets who expose metrics through an HTTP endpoint
- Scraped metrics are then stored in a time series database which can be queried using Prometheus' built-in query language PromQl.
- diffrent kind of metrics can Prometheus Monitor :-
    • CPU/Memory Utilization
    • Disk space
    • Service Uptime
    • Application specific data
        • Number of exceptions
        • Latency
        • Pending Requests
- prometheus monitor numeric data. it  is designed to monitor time-series data
that is numeric.
- type of data should Prometheus not monitor
    • Events
    • System logs
    • Traces
## Prometheus Architecture
- it have main 3 parts :-
    1. Retrieval(Scrapes metric data)= it sends the http request to data base and collect the data.
    2. TSDB(time series db)= it store metric data.
    3. HTTP Server(Accepts PromQL Query)= it accept the query string from user and accorting to query it give graph.
- exporters= it responsible for taking internal data fro db and converting it into a metric that Prometheus will understand.
    Prometheus has several native exporters
    • Node exporters(Linux servers)
    • Windows
    • MySQL
    • Apache
    • HAProxy
- short-lived-job= in this job we have to push the data to promethus bcz the job doesn`t able to scrap it.you use short-lived-job to send data to a pushgateway.
- pushgateway= Peomethus can then query the data from the gateway like any other target.
- serviceDiscovery= it provides a list of targets for prometheus to escape so that you dont have to hard code those values. ex:- aws, kubernetes.
- AlertManager = Promethus doest not send sms/email,it only genreate the alert.AlertManager send all the sms/email to user according to alert.
- Promethus Web UI and grafana use PromQL, send http request.
- Prometheus collect metrics by  sending http requests to "/metrics" endpoint of each target. we can the "/metrics" folder in configuartion file.
- Prometheus comes with client libraries that allow you to expose any application metrics you need Prometheus to track.      
    Language support:
        • Go
        • Java
        • Python
        • Ruby
        • Rust
- Promethus follows pull base model.In a pushed based model, the targets are configured to push the metric data to the metrics server.
    why pull?
    - easy to know,if target is down.
    - it handle overload data in metrics
    - it have s list of target.

## Prometheus – Node Exporter
download=
-->wget https://github.com/prometheus/node_exporter/releases/download/v1.3.1/node_exporter-1.3.1.linux-amd64.tar.gz
-->tar -xvf node_exporter-1.3.1.linux-amd64.tar.gz
-->cd node_exporter-1.3.1. linux-amd64
-->ls -l
to start the process
-->./node_exporter

-->curl localhost:9100/metrics
## Prometheus Configuration
it have following sections=
- global= Default parameters for all other config sections
- scrap_config=Define targets & configs for metrics collection
    - job name=A collection of instances that need to be scraped.
    - Configs for scrape job. Takes precedence over global config.
    - static_config:-set of targets to scrape.

## Prometheus – Metrics
- TimeStamp= When Prometheus scrapes a target and retrieves metrics, it also stores the time at which the metric was scraped as well.
    - The timestamp will look like this: 1668215300
    - This is called a unix timestamp, which is the number of seconds that have elapsed since Epoch(January 1st 1970 UTC)
- matric attributes=
    2 types= 
    1. type= it tell type of promethus metrics.
    2. help=just provide a description of what the metric is.
- counter:-
    • How many times did X happen
    • Number can only increase
    why counter use:-
    1. total request
    2. total exception
    3. total of job execution
- Guage:-
    • what is the current value of X.
    • can go up or down.
    why guage use:-
    1. current cpu utilization
    2. available system memory
    3. number of concurrent requests.
- Histogram=
    - How long or how big something is
    - Groups observations into configurable bucket sizes
    it use for:-
    - response time
    - request size
- summary metrics=give o/p in %
    - Similar to histograms(track how long or how big)
    - How many observations fell below x
    - Don't have to define quantiles ahead of time
     use for=
    1. response time
    2. request size
- metric rules=
    1. Metric name specifies a general feature of a system to be measured
    2. May contain ASCIl letters, numbers, underscores, and colons
    3. Must match the regex [a-zA-Z_][a-zA-Z0-9]*
    4. Colons are reserved only for recording rules.
- labels= 
    1. Labels are Key-Value pairs associated with a metric
    2. Allows you to split up a metric by a specified criteria
    3. Metric can have more than one label
    4. ASCII leters, numbers, underscores
    5. Must match regex [a-zA-ZO-9_]*
    Q.why label=
    A. if we have request from diffrent apis path , so its difficult to find sum of all request from different paths withoud label.
    but the label you can calculate all request. 
    ex:-Sum all requests: sum(requests_total)
        requests_total{path=/auth}
        requests_total{path=/uer}
        requests_total{path=/products}
    # mulitiple lables=
    requests_total{path=/auth, method=get}
    # internal Label= 
        - Labels surrounded by are considered internal to prometheus
        - Metric name is just another label
        ex:- "node_cpu_seconds_total{cpu=0}" equivaluent to "{__name__=node_cpu_seconds_total, cpu=0}"
    # Every metric is assigned 2 labels by default(instance and job)

## Prometheus – Monitoring Containers
- Metrics can also be scraped from containerized environments
    metrics record by=
    steps for connect promethus to docker=
    1. Docker Engine Metrics
    - 1. add promethus ip in docker container=
    -->vi / etc/docker/daemon. json
    -->sudo systemcti restart docker
    -->curl localhost:9323/metrics
    # daemon.json
    {   "metrics-addr" : "127.0.0.1:9323",
        "experimental" : true
    }
     2. add docker in promethus configuration file=
     scrape_configs:
        - job_name: "docker"
          static_configs:*
            - targets: ["12.1.13.4:9323"]
    - metrics example=
        1. How much cpu does docker use
        2. Total number of failed image builds
        3. Time to process container actions
        4. No metrics specific to a container
    2. Container metrics using CAdvisor=
    steps for connect docker and promethus via Cadvisor 
        1. in docker
        -->vi docker-compose. yml
        # docekr-compose.yml
        -->docker-compose up
        -->curl localhost:8080/metrics
        2. add docker in promethus configuration file=
         scrape_configs:
            - job_name: "docker"
              static_configs:*
                - targets: ["12.1.13.4:9323"]
    - metrics example=
        1. How much cpu/mem does each container use
        2. Number of processes running inside a container
        3. Container uptime
        4. Metrics on a per container basis

## Prometheus – Monitoring Kubernetes
- we run promethus in kubernetes by using pre-exisitng infrastructure.
- Monitor applications running on Kubernetes infrastructure
- Monitor Kubernetes Cluster
    • Control-Plane Components(api-server, coredns, kube-scheduler)
    • Kubelet(cAdvisor) - exposing container metrics
    • Kube-state-metrics - cluster level metrics(deployments, pod-metrics)
    • Node-exporter - Run on all nodes for host related metrics(cpu,
    mem, network)
- by default we unable to collect by default cluster level metrics.for this we have to install "kube-state-metrics" into our kubernetes cluster evironment.
- Kubernetes daemonSet will automatically assign a pod to that node that's going to contain the node-exporter process.
- # deploy promethus in kubernetes cluster = 
    - Best way to deploy Prometheus is using Helm chart to deploy Prometheus operator.
    - Helm is a package manager for Kubernetes 
    - All application and Kubernetes configs necessary for an application can be bundled into a package and easily deployed.
    - cmd for help install
    --> helm install
    - # Helm Charts 
        - helm chart is a collection of template & YAML files that convert into Kubernetes manifest files.
        - Helm charts can be shared with others by uploading a chart to a repository.
        - helm chart repo=
            Repository: Prometheus-community
            Chart: kube-Prometheus-stack
# Kube-Prometheus-stack
- The Kube-Prometheus-stack chart makes use of the Prometheus Operator.
- A Kubernetes operator is an application-specific controller that extends the K8s API to create/configure/manage instances of complex applications(like Prometheus!).

# Prometheus Operator
The Prometheus operator has several custom resources to aid the deployment and management of a Prometheus instance.
    # prometeus-kubernetes.yaml
## Cost Management
- right infrastructure
    -  on demand=prevalent,flexible,expensive,on-demand
    - reserved instance=
    - spot instances=
- Managing Performance and Cost through rightsizing=autoscalling by kubernetes.
    - Configuring optimal upper and lower limits.
    - Selecting appropriate performance metrics.
- Scheduling non-essential instances and removing unused resources
- conclusion= cloud provider provide cost managaement tool
    - aws=aws cost explorer
    - azure=azure cost management,azure billing
